{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "import praw\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\seb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the VADER lexicon\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "env = dotenv_values('./.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Reddit API credentials\n",
    "reddit = praw.Reddit(\n",
    "    client_id=env['R_CLIENT_ID'],\n",
    "    client_secret=env['R_CLIENT_SECRET'],\n",
    "    user_agent=env['R_USER_AGENT']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "praw.models.Submission: \n",
    "https://praw.readthedocs.io/en/v7.7.1/code_overview/models/submission.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream post submissions in selected subreddit and analyze sentiment\n",
    "subreddit_name = 'Economics'\n",
    "\n",
    "subreddit = reddit.subreddit(subreddit_name)\n",
    "submission_data = {}  # submission data storage\n",
    "\n",
    "for submission in subreddit.stream.submissions():\n",
    "    if submission.stickied:  # if post is pinned, skip it\n",
    "        continue\n",
    "    if not submission.selftext:  # if post doesn't contain text, skip it\n",
    "        continue\n",
    "    \n",
    "    sentiment = sia.polarity_scores(submission.selftext)\n",
    "\n",
    "    submission_data[f\"{submission.id}\"] = {\n",
    "        'id': submission.id,\n",
    "        'created_utc': int(submission.created_utc),\n",
    "        'num_comments': submission.num_comments,\n",
    "        'score': submission.score,\n",
    "        'upvote_ratio': submission.upvote_ratio,\n",
    "        'sentiment': sentiment['compound']\n",
    "    }\n",
    "    \n",
    "    #database.insert_row('sentiment', submission_data)\n",
    "\n",
    "    print(list(submission_data.items())[-1])\n",
    "    for comment in submission.comments:\n",
    "        print(comment.selftext)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
